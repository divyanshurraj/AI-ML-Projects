{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e95c56",
   "metadata": {},
   "source": [
    "# Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f9d83",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "805c0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#from glob import glob\n",
    "\n",
    "#import cv2\n",
    "#import random\n",
    "\n",
    "#import os\n",
    "#%matplotlib inline\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.preprocessing.layers import Dense, Input, Dropout, Flatten, Conv2D\n",
    "#from tensorflow.keras.preprocessing.layers import BatchNormalisation, Activation, Maxpooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    " import cv2\n",
    "import dlib\n",
    "import speech_recognition as sr\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load Pre-trained Emotion Detection Model\n",
    "emotion_model = load_model(r'C:/Users/INDIAN/Desktop/emotional_detection')\n",
    "\n",
    "# Initialize Dlib's face detector and facial landmarks predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(r'C:\\Users\\INDIAN\\Desktop\\landmarks.data')\n",
    "\n",
    "# Initialize SpeechRecognition recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Load pre-trained eye state detection model\n",
    "# You may need to train or obtain a pre-trained model for this task\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Emotion Detection\n",
    "    # Your code for extracting faces and predicting emotions using emotion_model\n",
    "\n",
    "    # Speech Analysis\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something:\")\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        voice_text = recognizer.recognize_google(audio)\n",
    "        # Your code for analyzing voice tone using voice_text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "\n",
    "    # Eye State Analysis\n",
    "    # Your code for detecting eye state using the pre-trained eye state model\n",
    "\n",
    "    # Your code for combining the results and deciding on the overall emotion\n",
    "\n",
    "    # Display the frame with results\n",
    "    cv2.imshow('Real-Time Emotion Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b1abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
